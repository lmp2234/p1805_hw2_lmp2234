p1805_hw2_lmp2234
================
Lisa Pardee
2024-10-02

**Question 1**

``` r
library(tidyverse)
library(dplyr)
```

**Reading in the NYC Transit Subway File**

``` r
subway_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
subway_df = janitor::clean_names(subway_df)
```

**Keeping Certain Variables and Changing Entry to a Logical Variable**

``` r
subway_df <-subway_df %>%
select(line:vending,ada)

subway_df = subway_df %>%
  mutate(entry_logical = case_match(entry,
                                    "YES" ~ TRUE,
                                    "NO" ~ FALSE))

subway_df
```

    ## # A tibble: 1,868 × 21
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 14 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>,
    ## #   entrance_type <chr>, entry <chr>, exit_only <chr>, vending <chr>,
    ## #   ada <lgl>, entry_logical <lgl>

``` r
skimr::skim(subway_df)
```

|                                                  |           |
|:-------------------------------------------------|:----------|
| Name                                             | subway_df |
| Number of rows                                   | 1868      |
| Number of columns                                | 21        |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |           |
| Column type frequency:                           |           |
| character                                        | 13        |
| logical                                          | 2         |
| numeric                                          | 6         |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |           |
| Group variables                                  | None      |

Data summary

**Variable type: character**

| skim_variable | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:--------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| line          |         0 |          1.00 |   5 |  17 |     0 |       36 |          0 |
| station_name  |         0 |          1.00 |   4 |  39 |     0 |      356 |          0 |
| route1        |         0 |          1.00 |   1 |   2 |     0 |       24 |          0 |
| route2        |       848 |          0.55 |   1 |   2 |     0 |       20 |          0 |
| route3        |      1374 |          0.26 |   1 |   2 |     0 |       18 |          0 |
| route4        |      1547 |          0.17 |   1 |   1 |     0 |       13 |          0 |
| route5        |      1630 |          0.13 |   1 |   1 |     0 |       12 |          0 |
| route6        |      1741 |          0.07 |   1 |   1 |     0 |        7 |          0 |
| route7        |      1788 |          0.04 |   1 |   2 |     0 |        7 |          0 |
| entrance_type |         0 |          1.00 |   4 |   9 |     0 |        7 |          0 |
| entry         |         0 |          1.00 |   2 |   3 |     0 |        2 |          0 |
| exit_only     |      1812 |          0.03 |   3 |   3 |     0 |        1 |          0 |
| vending       |         0 |          1.00 |   2 |   3 |     0 |        2 |          0 |

**Variable type: logical**

| skim_variable | n_missing | complete_rate | mean | count               |
|:--------------|----------:|--------------:|-----:|:--------------------|
| ada           |         0 |             1 | 0.25 | FAL: 1400, TRU: 468 |
| entry_logical |         0 |             1 | 0.94 | TRU: 1753, FAL: 115 |

**Variable type: numeric**

| skim_variable     | n_missing | complete_rate |   mean |   sd |     p0 |    p25 |    p50 |    p75 |   p100 | hist  |
|:------------------|----------:|--------------:|-------:|-----:|-------:|-------:|-------:|-------:|-------:|:------|
| station_latitude  |         0 |          1.00 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| station_longitude |         0 |          1.00 | -73.94 | 0.06 | -74.03 | -73.99 | -73.96 | -73.91 | -73.76 | ▇▆▃▂▁ |
| route8            |      1820 |          0.03 |   2.98 | 1.94 |   1.00 |   1.00 |   4.00 |   5.00 |   5.00 | ▇▁▁▂▇ |
| route9            |      1840 |          0.01 |   2.54 | 1.17 |   2.00 |   2.00 |   2.00 |   2.00 |   5.00 | ▇▁▁▁▂ |
| route10           |      1845 |          0.01 |   3.00 | 0.00 |   3.00 |   3.00 |   3.00 |   3.00 |   3.00 | ▁▁▇▁▁ |
| route11           |      1845 |          0.01 |   7.00 | 0.00 |   7.00 |   7.00 |   7.00 |   7.00 |   7.00 | ▁▁▇▁▁ |

**The NYC Subway dataset contains 1868 rows and 21 columns after
retaining specific variable names and adding an additional variable
“entry_logical” that converted the entry variable from character to
logical. The dataset contains information about subway lines, station
names, latitude/longitude, the routes the subways take, entrance type,
whether the station allows entry or is exit only, whether the station
has vending, and whether it is ADA compliant. The variable names were
cleaned using clean_names from the janitor function, only columns “line”
through “vending” and “ada” were retained, and case_match was used to
convert entry to a logical variable. This data is tidy since each
variable has a column name and the observations are organized by rows.
Only relevant information about subway lines, routes, and station
features are retained.**

**How Many Distinct Stations Are There**

``` r
distinct_stations <- subway_df %>%
  distinct(station_name, line) %>%
  nrow()

distinct_stations
```

    ## [1] 465

**How Many Stations are ADA Compliant**

``` r
ada_compliant_stations <- subway_df %>%
  filter(ada == TRUE) %>%
  distinct (station_name) %>%
   nrow()

ada_compliant_stations
```

    ## [1] 73

**Proportion of station entrances/exits without vending allow entrance**

``` r
proportion_entry <- subway_df %>%
  filter (vending == "No")  %>%
   summarise(proportion = mean(entry_logical, na.rm = TRUE)) 

proportion_entry
```

    ## # A tibble: 1 × 1
    ##   proportion
    ##        <dbl>
    ## 1        NaN

**There were no station entrances and exits without vending that allow
entrance.**

``` r
subway_df <- subway_df %>%
  mutate(across(starts_with("route"), as.character))

subway_long <- subway_df %>%
  pivot_longer(
    route1:route11, 
    names_to = "route_name", 
    values_to = "route_number")

subway_long
```

    ## # A tibble: 20,548 × 12
    ##    line     station_name station_latitude station_longitude entrance_type entry
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>         <chr>
    ##  1 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  2 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  3 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  4 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  5 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  6 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  7 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  8 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ##  9 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ## 10 4 Avenue 25th St                  40.7             -74.0 Stair         YES  
    ## # ℹ 20,538 more rows
    ## # ℹ 6 more variables: exit_only <chr>, vending <chr>, ada <lgl>,
    ## #   entry_logical <lgl>, route_name <chr>, route_number <chr>

``` r
a_stations <- subway_long %>%
  filter(route_number=="A") %>%  
  distinct(station_name, line) %>%
  nrow()

a_stations
```

    ## [1] 60

``` r
ada_compliant <-subway_long  %>%
  filter (route_number=="A", ada == TRUE) %>%
  distinct(station_name, line) %>%
  nrow()

ada_compliant
```

    ## [1] 17

**60 stations serve the A train** **Of the stations that serve the A
train 17, are ADA compliant**

**Question 2**

``` r
library(readxl)


mrtrashwheel_df <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Mr. Trash Wheel", 
                               skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(sports_balls = as.integer(round(sports_balls))) |> 
  select(-x15, -x16)  

head(mrtrashwheel_df, 5)
```

    ## # A tibble: 5 × 14
    ##   dumpster month year  date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ## 1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ## 2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ## 3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ## 4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ## 5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

``` r
professortrashwheel_df <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Professor Trash Wheel", 
                               skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster)|>  
  mutate(year = as.character(year))

head(professortrashwheel_df, 5)
```

    ## # A tibble: 5 × 13
    ##   dumpster month    year  date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ## 1        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ## 2        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ## 3        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ## 4        4 February 2017  2017-02-26 00:00:00        3.72                 15
    ## 5        5 February 2017  2017-02-28 00:00:00        1.45                 15
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
gwynndatrashwheel_df <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                               sheet = "Gwynnda Trash Wheel", 
                               skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
mutate(year = as.character(year))

head(gwynndatrashwheel_df, 5)
```

    ## # A tibble: 5 × 12
    ##   dumpster month year  date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ## 1        1 July  2021  2021-07-03 00:00:00        0.93                 15
    ## 2        2 July  2021  2021-07-07 00:00:00        2.26                 15
    ## 3        3 July  2021  2021-07-07 00:00:00        1.62                 15
    ## 4        4 July  2021  2021-07-16 00:00:00        1.76                 15
    ## 5        5 July  2021  2021-07-30 00:00:00        1.53                 15
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

**Combining the datasets**

``` r
mrtrashwheel_df <- mrtrashwheel_df |> 
  mutate(source = "Mr. Trash Wheel") 

professortrashwheel_df <- professortrashwheel_df |> 
  mutate(source = "Professor Trash Wheel") 

gwynndatrashwheel_df <- gwynndatrashwheel_df |> 
  mutate(source = "Gwynndat Trash Wheel")

combined_df = bind_rows(mrtrashwheel_df, professortrashwheel_df, gwynndatrashwheel_df)

head(combined_df, 5)
```

    ## # A tibble: 5 × 15
    ##   dumpster month year  date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ## 1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ## 2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ## 3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ## 4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ## 5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, source <chr>

The `combined_df` dataset consists of 1033 observations and 15 variables
from three datasheets: Mr. Trash Wheel, Gwynnda Trash Wheel, and
Professor Trash Wheel. The `Mr. Trash Wheel` dataset has 651
observations. The `Professor Trash Wheel` dataset has 119 observations.
The `Gwynnda Trash Wheel` dataset has 263 observations. Key variables in
this set include the `date` of trash collection, the `weight_tons` which
notes the weight of the trash collected, and the contents of what was
collected in the trash such as number of `cigarette_butts`. The total
weight of trash collected by `Professor Trash Wheel` is 246.74 pounds.
In June 2022, `Gwynnda Trash Wheel` collected 18,120 cigarette butts.

**Question 3**

``` r
library(readxl)

bakers_df <- read_csv("./data/bakers.csv") %>%
  janitor::clean_names() %>%
  rename(baker = baker_name) %>%
  select(-baker_age,-baker_occupation, -hometown)
  
bakes_df <- read_csv("./data/bakes.csv") %>%
  janitor::clean_names() %>%
  relocate(baker)%>%
  select(-signature_bake, -show_stopper)

results_df <- read_csv("./data/results.csv", skip = 2) %>%
  janitor::clean_names() %>%
  relocate(baker) %>%
  mutate(result = str_trim(result),  
         result = case_when(
           str_to_title(result) %in% c("Winner", "Star Baker") ~ "TRUE",  
           TRUE ~ "FALSE"
         ))

head(bakers_df, 5)
```

    ## # A tibble: 5 × 2
    ##   baker            series
    ##   <chr>             <dbl>
    ## 1 Ali Imdad             4
    ## 2 Alice Fevronia       10
    ## 3 Alvin Magallanes      6
    ## 4 Amelia LeBruin       10
    ## 5 Andrew Smyth          7

``` r
head(bakes_df, 5)
```

    ## # A tibble: 5 × 3
    ##   baker     series episode
    ##   <chr>      <dbl>   <dbl>
    ## 1 Annetha        1       1
    ## 2 David          1       1
    ## 3 Edd            1       1
    ## 4 Jasminder      1       1
    ## 5 Jonathan       1       1

``` r
head(results_df, 5)
```

    ## # A tibble: 5 × 5
    ##   baker     series episode technical result
    ##   <chr>      <dbl>   <dbl>     <dbl> <chr> 
    ## 1 Annetha        1       1         2 FALSE 
    ## 2 David          1       1         3 FALSE 
    ## 3 Edd            1       1         1 FALSE 
    ## 4 Jasminder      1       1        NA FALSE 
    ## 5 Jonathan       1       1         9 FALSE

``` r
missing_bakes <- anti_join(bakes_df, bakers_df, by = "baker")
missing_results <- anti_join(results_df, bakers_df, by = "baker")

print(missing_bakes)
```

    ## # A tibble: 548 × 3
    ##    baker     series episode
    ##    <chr>      <dbl>   <dbl>
    ##  1 Annetha        1       1
    ##  2 David          1       1
    ##  3 Edd            1       1
    ##  4 Jasminder      1       1
    ##  5 Jonathan       1       1
    ##  6 Lea            1       1
    ##  7 Louise         1       1
    ##  8 Mark           1       1
    ##  9 Miranda        1       1
    ## 10 Ruth           1       1
    ## # ℹ 538 more rows

``` r
print(missing_results)
```

    ## # A tibble: 1,136 × 5
    ##    baker     series episode technical result
    ##    <chr>      <dbl>   <dbl>     <dbl> <chr> 
    ##  1 Annetha        1       1         2 FALSE 
    ##  2 David          1       1         3 FALSE 
    ##  3 Edd            1       1         1 FALSE 
    ##  4 Jasminder      1       1        NA FALSE 
    ##  5 Jonathan       1       1         9 FALSE 
    ##  6 Louise         1       1        NA FALSE 
    ##  7 Miranda        1       1         8 FALSE 
    ##  8 Ruth           1       1        NA FALSE 
    ##  9 Lea            1       1        10 FALSE 
    ## 10 Mark           1       1        NA FALSE 
    ## # ℹ 1,126 more rows

``` r
combined_df <- bakes_df%>%
left_join(results_df, by = c("baker", "series", "episode"))%>%
left_join(bakers_df, by = c("baker","series"))%>%
select (baker, series, episode, technical, result)

head(combined_df, 5)
```

    ## # A tibble: 5 × 5
    ##   baker     series episode technical result
    ##   <chr>      <dbl>   <dbl>     <dbl> <chr> 
    ## 1 Annetha        1       1         2 FALSE 
    ## 2 David          1       1         3 FALSE 
    ## 3 Edd            1       1         1 FALSE 
    ## 4 Jasminder      1       1        NA FALSE 
    ## 5 Jonathan       1       1         9 FALSE

**Data Cleaning Process** I cleaned the data by first reading in the
data files and cleaned the variable names. For the bakers_df I removed
the columns that corresponded to baker age, baker occupation, and
hometown.I also renamed the baker_name variable to baker because the
other two datasets had the name as baker. For bakes_df, I relocated
baker column so that it was the first column. i then removed signature
bake and show stopper since they were not relevant. For results_df, I
skipped the first two rows since they did not contain any information
and the column names started on the third row. I also relocated the
baker column to be first. I then mutated the result variable so that if
the column said Winner or Star Baker, then it was coded as True, or else
it was coded as false. This made it easier to create a table showing
star baker/winner of season 5.I merged the datasets with left_join. i
first joined the bakes and results datasets as they shared baker,
series, and episode variables in common. I then merged this with
bakers_df by baker and series. I selected the column names in order of
appearance. This yielded a dataset that contained information on the
baker name, series they appeared in, episode they appeared in, number of
technical challenges, and the results of the episode.

**Exporting the Data**

``` r
write_csv(combined_df, "./data/combined_df.csv")
```

**Creating table showing star baker or winner of season 5 through 10. **

``` r
star_table <- combined_df %>%
  filter(series >= 5 & series <= 10) %>%
  filter(result == "TRUE") %>%
  select(series, episode, baker) %>%
  arrange(series, episode)

print(star_table)
```

    ## # A tibble: 40 × 3
    ##    series episode baker  
    ##     <dbl>   <dbl> <chr>  
    ##  1      5       1 Nancy  
    ##  2      5       2 Richard
    ##  3      5       3 Luis   
    ##  4      5       4 Richard
    ##  5      5       5 Kate   
    ##  6      5       6 Chetna 
    ##  7      5       7 Richard
    ##  8      5       8 Richard
    ##  9      5       9 Richard
    ## 10      5      10 Nancy  
    ## # ℹ 30 more rows

**Importing and Tidying the Viewers Data**

``` r
viewers_df <- read_csv("./data/viewers.csv") %>%
  janitor::clean_names()

newviewers_df<- viewers_df  %>%
  pivot_longer(cols = starts_with("series_"), 
               names_to = "series", 
               values_to = "value")

head(newviewers_df, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series    value
    ##      <dbl> <chr>     <dbl>
    ##  1       1 series_1   2.24
    ##  2       1 series_2   3.1 
    ##  3       1 series_3   3.85
    ##  4       1 series_4   6.6 
    ##  5       1 series_5   8.51
    ##  6       1 series_6  11.6 
    ##  7       1 series_7  13.6 
    ##  8       1 series_8   9.46
    ##  9       1 series_9   9.55
    ## 10       1 series_10  9.62

**Average Viewership for Season 1**

``` r
viewership_season_1 <- newviewers_df %>%
  filter(series == "series_1") %>%
  summarise(viewership_season_1 = mean(value, na.rm = TRUE))

viewership_season_1
```

    ## # A tibble: 1 × 1
    ##   viewership_season_1
    ##                 <dbl>
    ## 1                2.77

**Average Viewership for Season 5**

``` r
viewership_season_5 <- newviewers_df %>%
  filter(series == "series_5") %>%
  summarise(viewership_season_5 = mean(value, na.rm = TRUE))

viewership_season_5
```

    ## # A tibble: 1 × 1
    ##   viewership_season_5
    ##                 <dbl>
    ## 1                10.0
